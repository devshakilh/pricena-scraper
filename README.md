
# ğŸ“¦ PricePoka Scraper API

A **TypeScript-based web scraper API** for fetching product data (name, price, image, and link) from multiple e-commerce websites, including **Rokomari** and popular **UK platforms** like **Amazon UK**, **eBay UK**, **Tesco**, and more.

---

## âœ¨ Features

- ğŸ” Scrapes product details from **11+ e-commerce sites**
- âš™ï¸ Robust error handling with **Winston logging**
- ğŸ” Fully typed with **TypeScript** for maintainability
- ğŸ¨ Code quality enforced via **Prettier**, **ESLint**, and **Husky hooks**
- âš¡ Uses **pnpm** for fast and reliable package management

---

## ğŸ“¦ Prerequisites

- [Node.js](https://nodejs.org/) (>= 18.x)
- [pnpm](https://pnpm.io/) (>= 8.x)

---

## ğŸš€ Installation

```bash
# Clone the repository
git clone <repository-url>
cd pricepoka-scraper

# Install dependencies
pnpm install

# Create a .env file
echo "PORT=5000" > .env

# Build the project
pnpm build
```

---

## ğŸ”§ Usage

```bash
# Start the production server
pnpm start

# OR start in development mode with hot reload
pnpm dev
```

### âœ… Example API Call

```bash
curl http://localhost:5000/scrape/laptop
```

---

## ğŸŒ API Endpoint

### `GET /scrape/:product`

Fetches product data from all configured e-commerce platforms.

**Response (JSON):**
```json
[
  {
    "name": "Amazon UK",
    "logo": "https://...logo.png",
    "products": [
      {
        "id": "uuid",
        "name": "Product Title",
        "price": "$99.99",
        "img": "https://...image.jpg",
        "link": "https://...product-url"
      }
    ]
  },
  ...
]
```

---

## ğŸ—‚ï¸ Project Structure

```
pricepoka-scraper/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config/         # Scraper configurations
â”‚   â”œâ”€â”€ controllers/    # API logic
â”‚   â”œâ”€â”€ interfaces/     # TypeScript interfaces
â”‚   â”œâ”€â”€ middlewares/    # Middleware functions
â”‚   â”œâ”€â”€ routes/         # API routes
â”‚   â”œâ”€â”€ services/       # Scraper services
â”‚   â”œâ”€â”€ utils/          # Utility functions
â”‚   â”œâ”€â”€ scrapers/       # Individual scraper implementations
â”‚   â”œâ”€â”€ app.ts          # Express app setup
â”‚   â””â”€â”€ server.ts       # Entry point
â”œâ”€â”€ logs/               # Winston log output
â”œâ”€â”€ .husky/             # Git hooks
â”œâ”€â”€ .env                # Environment config
â”œâ”€â”€ package.json
â”œâ”€â”€ tsconfig.json
â”œâ”€â”€ .eslintrc.json
â”œâ”€â”€ .prettierrc
```

---

## ğŸ›  Scripts

| Script         | Description                    |
|----------------|--------------------------------|
| `pnpm start`   | Run the production server      |
| `pnpm dev`     | Start dev server with hot reload |
| `pnpm build`   | Compile TypeScript             |
| `pnpm lint`    | Run ESLint                     |
| `pnpm format`  | Format code with Prettier      |

---

## ğŸ› Debugging

- All logs are saved in:
  - `logs/app.log` (general logs)
  - `logs/error.log` (errors)
- If no data is returned (e.g., â€œLink not foundâ€), check:
  - The siteâ€™s HTML structure (selectors might have changed)
  - The relevant scraper in `src/scrapers/*.scraper.ts`

---

## ğŸ¤ Contributing

1. Fork the repository
2. Create your feature branch: `git checkout -b feature-name`
3. Commit your changes: `git commit -m "Add feature"`
4. Push to the branch: `git push origin feature-name`
5. Open a pull request ğŸš€
